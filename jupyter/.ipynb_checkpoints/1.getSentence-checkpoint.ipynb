{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将XML文件中的基金描述提取出来，并且分句存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读XML文件，提取基金描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "from xml.etree.ElementTree import parse\n",
    "import os\n",
    "\n",
    "filePath = '/Users/haohao/Documents/fundingsView/data/raw/1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获得文件夹下的所有文件名称，并将文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1900542.xml',\n",
       " '1900393.xml',\n",
       " '1900422.xml',\n",
       " '1900344.xml',\n",
       " '1900621.xml',\n",
       " '1900423.xml',\n",
       " '1900392.xml',\n",
       " '1900386.xml',\n",
       " '1900594.xml',\n",
       " '1900541.xml',\n",
       " '1900555.xml',\n",
       " '1900390.xml',\n",
       " '1900384.xml',\n",
       " '1900636.xml',\n",
       " '1900420.xml',\n",
       " '1900434.xml',\n",
       " '1900391.xml',\n",
       " '1900540.xml',\n",
       " '1900568.xml',\n",
       " '1900583.xml',\n",
       " '1900430.xml',\n",
       " '1900626.xml',\n",
       " '1900633.xml',\n",
       " '1900357.xml',\n",
       " '1900380.xml',\n",
       " '1900590.xml',\n",
       " '1900396.xml',\n",
       " '1900340.xml',\n",
       " '1900397.xml',\n",
       " '1900509.xml',\n",
       " '1900482.xml',\n",
       " '1900643.xml',\n",
       " '1900483.xml',\n",
       " '1900534.xml',\n",
       " '1900285.xml',\n",
       " '1900536.xml',\n",
       " '1900456.xml',\n",
       " '1900324.xml',\n",
       " '1900457.xml',\n",
       " '1900296.xml',\n",
       " '1900321.xml',\n",
       " '1900651.xml',\n",
       " '1900644.xml',\n",
       " '1900491.xml',\n",
       " '1900532.xml',\n",
       " '1900295.xml',\n",
       " '1900646.xml',\n",
       " '1900652.xml',\n",
       " '1900647.xml',\n",
       " '1900451.xml',\n",
       " '1900445.xml',\n",
       " '1900519.xml',\n",
       " '1900294.xml',\n",
       " '1900299.xml',\n",
       " '1900272.xml',\n",
       " '1900500.xml',\n",
       " '1900460.xml',\n",
       " '1900475.xml',\n",
       " '1900271.xml',\n",
       " '1900463.xml',\n",
       " '1900462.xml',\n",
       " '1900476.xml',\n",
       " '1900338.xml',\n",
       " '1900502.xml',\n",
       " '1900506.xml',\n",
       " '1900300.xml',\n",
       " '1900301.xml',\n",
       " '1900473.xml',\n",
       " '1900507.xml',\n",
       " '1900288.xml',\n",
       " '1900277.xml',\n",
       " '1900317.xml',\n",
       " '1900464.xml',\n",
       " '1900510.xml',\n",
       " '1900563.xml',\n",
       " '1900359.xml',\n",
       " '1900417.xml',\n",
       " '1900600.xml',\n",
       " '1900416.xml',\n",
       " '1900364.xml',\n",
       " '1900358.xml',\n",
       " '1900562.xml',\n",
       " '1900589.xml',\n",
       " '1900560.xml',\n",
       " '1900399.xml',\n",
       " '1900366.xml',\n",
       " '1900603.xml',\n",
       " '1900617.xml',\n",
       " '1900401.xml',\n",
       " '1900575.xml',\n",
       " '1900549.xml',\n",
       " '1900377.xml',\n",
       " '1900411.xml',\n",
       " '1900606.xml',\n",
       " '1900612.xml',\n",
       " '1900570.xml',\n",
       " '1900599.xml',\n",
       " '1900572.xml',\n",
       " '1900406.xml',\n",
       " '1900374.xml',\n",
       " '1900348.xml',\n",
       " '1900638.xml',\n",
       " '1900349.xml',\n",
       " '1900375.xml',\n",
       " '1900567.xml']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbstract(file):\n",
    "    fileName = file\n",
    "    doc = parse(fileName)\n",
    "    root = doc.getroot()\n",
    "    childs = root.getchildren()\n",
    "\n",
    "    abstract = \"\"\n",
    "    for child0 in childs:\n",
    "        for child00 in child0.getchildren():\n",
    "            # print child00.tag #标签名，即name、date、price、description\n",
    "            # print child00.text\n",
    "            if child00.tag == \"AbstractNarration\":\n",
    "                abstract = child00.text\n",
    "    \n",
    "    re_br = re.compile('<br\\s*?/?>')\n",
    "    abstract = re_br.sub('', abstract)\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haohao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  \"\"\"\n",
      "/Users/haohao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "xmllist = os.listdir(filePath)\n",
    "file = xmllist[0]\n",
    "xml = filePath + file\n",
    "abstract = getAbstract(xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为该文件分句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_token_nltk(str):\n",
    "    sent_tokenize_list = sent_tokenize(str)\n",
    "    return sent_tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic biology and nanotechnology place increasing demands on design methodologies to ensure dependable and robust operation.\n",
      "Consisting of noisy and unreliable components, these complex systems have large and often infinite state spaces that include extremely rare error states.\n",
      "Stochastic model checking techniques have demonstrated significant potential in quantitatively analyzing such system models under extremely low probability.\n",
      "Unfortunately, they generally require enumerating the model's state space, which is computationally intractable or impossible.\n",
      "Therefore, addressing these design challenges in emerging technologies requires enhancing the applicability of stochastic model checking.\n",
      "Motivated by this problem, this project investigates an automated stochastic verification framework that integrates approximate stochastic model checking and counterexample-guided rare-event simulation to improve the analysis accuracy and efficiency.\n",
      "This project focuses on verifying infinite-state continuous-time Markov chain models with rare-event properties.\n",
      "It addresses the scalability problem by first applying property-guided and on-the-fly state truncation techniques to prune unlikely states to obtain finite state representations that are amenable to stochastic model checking.\n",
      "In the case of false or indeterminate verification results, stochastic counterexamples are generated and utilized to improve the accuracy of the state reductions.\n",
      "Furthermore, it mines these critical counterexamples as automated guidance to improve the quality and efficiency for rare-event stochastic simulations.\n",
      "This verification framework will be integrated within existing state-of-the-art stochastic model checking tools, and benchmarked on a wide range of real-world case studies in synthetic biology and nanotechnology.\n",
      "This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\n"
     ]
    }
   ],
   "source": [
    "sentences = sentence_token_nltk(abstract)\n",
    "for sen in sentences:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将分句的每句都存入txt文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfile = open(\"/Users/haohao/Documents/fundingsView/data/sentences/sentence1.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen in sentences:\n",
    "    wfile.write(sen+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def putSentences(filePath):\n",
    "    xmllist = os.listdir(filePath)\n",
    "    count = 0\n",
    "    for doc in xmllist:\n",
    "#         if count > 30:\n",
    "#             break\n",
    "        xml = filePath + doc\n",
    "        abstract = getAbstract(xml)\n",
    "        sentences = sentence_token_nltk(abstract)\n",
    "        for sen in sentences:\n",
    "            data = sen.strip('\\n')\n",
    "            if len(data) != 0:\n",
    "                wfile.write(data)\n",
    "                wfile.write('\\n')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haohao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  \"\"\"\n",
      "/Users/haohao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "putSentences(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
